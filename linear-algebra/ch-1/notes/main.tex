\documentclass[12pt]{article}
\usepackage{graphicx} % Required for inserting images
\usepackage[a4paper, total={6in, 10in}]{geometry}
\usepackage{datetime, xcolor, tcolorbox}
\usepackage{amsthm, thmtools, amsfonts, mathtools, amssymb}

\tcbuselibrary{theorems}

\newdateformat{monthyeardate}{\monthname[\THEMONTH] \THEYEAR}

\newtheorem{theorem}{Theorem}[section]
\newtheorem{corollary}{Corollary}[theorem]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{axiom}{Axiom}
\newtheorem{proposition}{Proposition}[section]
%\newtheorem{definition}{Definition}[section]
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\newtheorem*{notation}{Notation}

\definecolor{box-head}{rgb}{0, 0.435, 0.510}
\definecolor{box-body}{rgb}{0.506, 0.718, 0.757}

\newtcolorbox{important}[1][]{colframe=box-head, colback=box-body!28!, title=#1, fonttitle=\bfseries, before skip = 10pt}

\declaretheoremstyle[
    spaceabove=-6pt, 
    spacebelow=6pt, 
    headfont=\normalfont\bfseries, 
    bodyfont = \normalfont,
    headpunct={:}]{definitionstyle} 
\declaretheorem[name={Definition}, style=definitionstyle, numberwithin=section]{definition}

\let\oldvec = \vec
\renewcommand{\vec}[1]{\oldvec{\mathbf{#1}}}

\numberwithin{equation}{section}


\title{Linear Algebra}
\author{Riddhiman}
\date{\monthyeardate\today}

\begin{document}

\maketitle

\section{Preface}%
\label{sec:Preface}
Self study Linear Algebra notes. Source is \textit{Vector Calculus, Linear Algebra, and Differential Geometry} by John and Barbara Hubbard. These notes will start from Section 1.3. Notes for Sections 1.1 and 1.2 will be added later.

\section{Matrix Multiplication as Linear Transformation}%
\label{sec:Matrix Multiplication as Linear Transformation}

\begin{definition}[Linear transformation from $ \mathbb{R}^n $ to $ \mathbb{R}^m $]  
	A \textit{linear transformation} $ T : \mathbb{R}^{n} \rightarrow \mathbb{R}^{m} $ is a mapping such that for all scalars $ a $ and for all $ \vec{v}, \vec{w} \in \mathbb{R}^{n} $,
	\begin{equation}
		T(\vec{v} + \vec{w}) = T(\vec{v}) + T(\vec{w}) \text{ and } T(a\vec{v}) = aT(\vec{v})
	\end{equation}	
\end{definition}

This above was the definition of a linear transformation. The following theorem will relate matrices to linear transformation. 

\begin{important}[Theorem 2.1 (Matrices and linear transformation)]
	\begin{enumerate}
		\item Any $ m \times n $ matrix $ A $ defines a linear transformation $ T : \mathbb{R}^n \rightarrow \mathbb{R}^m $ is given by matrix multiplication: 
			\begin{equation}
				T(\vec{v}) = A \vec{v}.	
			\end{equation}
		\item Every linear transformation $ T : \mathbb{R}^n \rightarrow \mathbb{R}^m $ is given by multiplication by the $ m \times n $ matrix $ [T] $:
			\begin{equation}
				T(\vec{v}) = [T]\vec{v}, 
			\end{equation}
			where the $ i^{\text{th}} $ column of $ [T] $ is $ T(\vec{e}_{i}) $.
	\end{enumerate}
\end{important}

\begin{proof}[Proof to part 2 of Theorem 2.1] 
	Given that our domain is $ \mathbb{R}^n $ we can write any vector $ \vec{v} \in \mathbb{R}^n $ as \[\vec{v} = u_{1}\vec{e}_{1} + u_{2}\vec{e}_{2} + \ldots + u_{n}\vec{e}_{n} = %
	\sum^{n}_{i=1} u_{i}\vec{e}_{i} \]
	Thus, 
	\begin{align*}
		T(\vec{v}) &= T\left(\sum^{n}_{i=1} u_{i}\vec{e}_{i}\right) \\ 
			   &= \sum^{n}_{i=1} u_{i}T(\vec{e}_{i}) 
	\end{align*}
	Also note that since every $ i^{\text{th}} $ column of $ [T] $ is $ T(\vec{e}_{i}) $. When $ [T] $ is multiplied by $ \vec{v} $, the $ i^{\text{th}} $ of the resultant column vector can be denoted as $ u_{1}T(\vec{e}_{1}) + \ldots + u_{n}T(\vec{e}_{n}) $ which is just $ T(\vec{v}) $. 
\end{proof}


\end{document}

